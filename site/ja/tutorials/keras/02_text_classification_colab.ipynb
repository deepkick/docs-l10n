{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic4_occAAiAT",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ioaprt5q5US7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yCl0eTNH5RS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXfxkxvosLH",
        "colab_type": "text"
      },
      "source": [
        "# 映画レビューのテキスト分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKY4XMc9o8iB",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKrWNcH6Xyz5",
        "colab_type": "text"
      },
      "source": [
        "Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg62Pmz3o83v",
        "colab_type": "text"
      },
      "source": [
        "ここでは、映画のレビューをそのテキストを使って**肯定的**か**否定的**かに分類します。これは、二値分類あるいは2クラス分類という問題の例であり、機械学習において重要でいろいろな応用が可能なものです。\n",
        "\n",
        "ここでは、[Internet Movie Database](https://www.imdb.com/)から抽出した50,000件の映画レビューを含む、 [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) を使います。レビューは訓練用とテスト用に25,000件ずつに分割されています。訓練用とテスト用のデータは**均衡**しています。言い換えると、それぞれが同数の肯定的及び否定的なレビューを含んでいます。\n",
        "\n",
        "ここでは、TensorFlowを使ってモデルを構築・訓練するためのハイレベルなAPIである [tf.keras](https://www.tensorflow.org/guide/keras)を使用します。`tf.keras`を使ったもう少し高度なテキスト分類のチュートリアルについては、 [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)を参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9030bf-5e3c-44e4-8e8f-5ca2c85267d8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsKG535pHep",
        "colab_type": "text"
      },
      "source": [
        "## IMDB datasetのダウンロード\n",
        "\n",
        "IMDBデータセットは、TensorFlowにパッケージ化されています。それは前処理済みのものであり、（単語の連なりである）レビューが、整数の配列に変換されています。そこでは整数が辞書中の特定の単語を表します。\n",
        "\n",
        "次のコードは、IMDBデータセットをあなたのパソコンにダウンロードします。（すでにダウンロードしていれば、キャッシュされたコピーを使用します）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXXx5Oc3pOmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc35c825-c514-496c-bcfd-9cd291140f83"
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odr-KlzO-lkL",
        "colab_type": "text"
      },
      "source": [
        "`num_words=10000`という引数は、訓練データ中に出てくる単語のうち、最も頻繁に出現する10,000個を保持するためのものです。データサイズを管理可能にするため、稀にしか出現しない単語は破棄されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l50X3GfjpU4r",
        "colab_type": "text"
      },
      "source": [
        "## データの観察\n",
        "\n",
        "データの形式を理解するために少し時間を割いてみましょう。このデータセットは前処理済みで、サンプルそれぞれが、映画レビューの中の単語を表す整数の配列になっています。ラベルはそれぞれ、0または1の整数値で、0が否定的レビュー、1が肯定的なレビューを示しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8qCnve_-lkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b6fe180-1cfc-4246-8438-dc9090f7da9c"
      },
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnKvHWW4-lkW",
        "colab_type": "text"
      },
      "source": [
        "レビューのテキストは複数の整数に変換されており、それぞれの整数が辞書の中の特定の単語を表します。最初のレビューがどのようなものか見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtTS4kpEpjbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f7d37f96-b9ff-47d7-ccb8-6dda937d4dc3"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIE4l_72x7DP",
        "colab_type": "text"
      },
      "source": [
        "映画のレビューはそれぞれ長さが異なっていることでしょう。次のコードで、最初と2つ目のレビューの単語の数を見てみます。ニューラルネットワークへの入力は同じ長さでなければならないため、後ほどその問題を解決する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-6Ii9Pfx6Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb304378-3782-4bd5-da1a-de28b9c40b07"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wJg2FiYpuoX",
        "colab_type": "text"
      },
      "source": [
        "### 整数を単語に戻してみる\n",
        "\n",
        "整数をテキストに戻す方法を知っていると便利です。整数を文字列にマッピングする辞書オブジェクトを検索するためのヘルパー関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr5s_1alpzop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e60401d3-ca2d-4ede-eb38-8097778c5e23"
      },
      "source": [
        "# 単語を整数にマッピングする辞書\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# インデックスの最初の方は予約済み\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CNRvEZVppl",
        "colab_type": "text"
      },
      "source": [
        "`decode_review`を使うと、最初のレビューのテキストを表示できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_OqxmH6-lkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "79eba5ca-9252-4560-9005-4e87da934c9d"
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMlkHDXwYwK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd84e30f-4a93-4902-afe5-47899db54dbe"
      },
      "source": [
        "word_index"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34704,\n",
              " 'tsukino': 52009,\n",
              " 'nunnery': 52010,\n",
              " 'sonja': 16819,\n",
              " 'vani': 63954,\n",
              " 'woods': 1411,\n",
              " 'spiders': 16118,\n",
              " 'hanging': 2348,\n",
              " 'woody': 2292,\n",
              " 'trawling': 52011,\n",
              " \"hold's\": 52012,\n",
              " 'comically': 11310,\n",
              " 'localized': 40833,\n",
              " 'disobeying': 30571,\n",
              " \"'royale\": 52013,\n",
              " \"harpo's\": 40834,\n",
              " 'canet': 52014,\n",
              " 'aileen': 19316,\n",
              " 'acurately': 52015,\n",
              " \"diplomat's\": 52016,\n",
              " 'rickman': 25245,\n",
              " 'arranged': 6749,\n",
              " 'rumbustious': 52017,\n",
              " 'familiarness': 52018,\n",
              " \"spider'\": 52019,\n",
              " 'hahahah': 68807,\n",
              " \"wood'\": 52020,\n",
              " 'transvestism': 40836,\n",
              " \"hangin'\": 34705,\n",
              " 'bringing': 2341,\n",
              " 'seamier': 40837,\n",
              " 'wooded': 34706,\n",
              " 'bravora': 52021,\n",
              " 'grueling': 16820,\n",
              " 'wooden': 1639,\n",
              " 'wednesday': 16821,\n",
              " \"'prix\": 52022,\n",
              " 'altagracia': 34707,\n",
              " 'circuitry': 52023,\n",
              " 'crotch': 11588,\n",
              " 'busybody': 57769,\n",
              " \"tart'n'tangy\": 52024,\n",
              " 'burgade': 14132,\n",
              " 'thrace': 52026,\n",
              " \"tom's\": 11041,\n",
              " 'snuggles': 52028,\n",
              " 'francesco': 29117,\n",
              " 'complainers': 52030,\n",
              " 'templarios': 52128,\n",
              " '272': 40838,\n",
              " '273': 52031,\n",
              " 'zaniacs': 52133,\n",
              " '275': 34709,\n",
              " 'consenting': 27634,\n",
              " 'snuggled': 40839,\n",
              " 'inanimate': 15495,\n",
              " 'uality': 52033,\n",
              " 'bronte': 11929,\n",
              " 'errors': 4013,\n",
              " 'dialogs': 3233,\n",
              " \"yomada's\": 52034,\n",
              " \"madman's\": 34710,\n",
              " 'dialoge': 30588,\n",
              " 'usenet': 52036,\n",
              " 'videodrome': 40840,\n",
              " \"kid'\": 26341,\n",
              " 'pawed': 52037,\n",
              " \"'girlfriend'\": 30572,\n",
              " \"'pleasure\": 52038,\n",
              " \"'reloaded'\": 52039,\n",
              " \"kazakos'\": 40842,\n",
              " 'rocque': 52040,\n",
              " 'mailings': 52041,\n",
              " 'brainwashed': 11930,\n",
              " 'mcanally': 16822,\n",
              " \"tom''\": 52042,\n",
              " 'kurupt': 25246,\n",
              " 'affiliated': 21908,\n",
              " 'babaganoosh': 52043,\n",
              " \"noe's\": 40843,\n",
              " 'quart': 40844,\n",
              " 'kids': 362,\n",
              " 'uplifting': 5037,\n",
              " 'controversy': 7096,\n",
              " 'kida': 21909,\n",
              " 'kidd': 23382,\n",
              " \"error'\": 52044,\n",
              " 'neurologist': 52045,\n",
              " 'spotty': 18513,\n",
              " 'cobblers': 30573,\n",
              " 'projection': 9881,\n",
              " 'fastforwarding': 40845,\n",
              " 'sters': 52046,\n",
              " \"eggar's\": 52047,\n",
              " 'etherything': 52048,\n",
              " 'gateshead': 40846,\n",
              " 'airball': 34711,\n",
              " 'unsinkable': 25247,\n",
              " 'stern': 7183,\n",
              " \"cervi's\": 52049,\n",
              " 'dnd': 40847,\n",
              " 'dna': 11589,\n",
              " 'insecurity': 20601,\n",
              " \"'reboot'\": 52050,\n",
              " 'trelkovsky': 11040,\n",
              " 'jaekel': 52051,\n",
              " 'sidebars': 52052,\n",
              " \"sforza's\": 52053,\n",
              " 'distortions': 17636,\n",
              " 'mutinies': 52054,\n",
              " 'sermons': 30605,\n",
              " '7ft': 40849,\n",
              " 'boobage': 52055,\n",
              " \"o'bannon's\": 52056,\n",
              " 'populations': 23383,\n",
              " 'chulak': 52057,\n",
              " 'mesmerize': 27636,\n",
              " 'quinnell': 52058,\n",
              " 'yahoo': 10310,\n",
              " 'meteorologist': 52060,\n",
              " 'beswick': 42580,\n",
              " 'boorman': 15496,\n",
              " 'voicework': 40850,\n",
              " \"ster'\": 52061,\n",
              " 'blustering': 22925,\n",
              " 'hj': 52062,\n",
              " 'intake': 27637,\n",
              " 'morally': 5624,\n",
              " 'jumbling': 40852,\n",
              " 'bowersock': 52063,\n",
              " \"'porky's'\": 52064,\n",
              " 'gershon': 16824,\n",
              " 'ludicrosity': 40853,\n",
              " 'coprophilia': 52065,\n",
              " 'expressively': 40854,\n",
              " \"india's\": 19503,\n",
              " \"post's\": 34713,\n",
              " 'wana': 52066,\n",
              " 'wang': 5286,\n",
              " 'wand': 30574,\n",
              " 'wane': 25248,\n",
              " 'edgeways': 52324,\n",
              " 'titanium': 34714,\n",
              " 'pinta': 40855,\n",
              " 'want': 181,\n",
              " 'pinto': 30575,\n",
              " 'whoopdedoodles': 52068,\n",
              " 'tchaikovsky': 21911,\n",
              " 'travel': 2106,\n",
              " \"'victory'\": 52069,\n",
              " 'copious': 11931,\n",
              " 'gouge': 22436,\n",
              " \"chapters'\": 52070,\n",
              " 'barbra': 6705,\n",
              " 'uselessness': 30576,\n",
              " \"wan'\": 52071,\n",
              " 'assimilated': 27638,\n",
              " 'petiot': 16119,\n",
              " 'most\\x85and': 52072,\n",
              " 'dinosaurs': 3933,\n",
              " 'wrong': 355,\n",
              " 'seda': 52073,\n",
              " 'stollen': 52074,\n",
              " 'sentencing': 34715,\n",
              " 'ouroboros': 40856,\n",
              " 'assimilates': 40857,\n",
              " 'colorfully': 40858,\n",
              " 'glenne': 27639,\n",
              " 'dongen': 52075,\n",
              " 'subplots': 4763,\n",
              " 'kiloton': 52076,\n",
              " 'chandon': 23384,\n",
              " \"effect'\": 34716,\n",
              " 'snugly': 27640,\n",
              " 'kuei': 40859,\n",
              " 'welcomed': 9095,\n",
              " 'dishonor': 30074,\n",
              " 'concurrence': 52078,\n",
              " 'stoicism': 23385,\n",
              " \"guys'\": 14899,\n",
              " \"beroemd'\": 52080,\n",
              " 'butcher': 6706,\n",
              " \"melfi's\": 40860,\n",
              " 'aargh': 30626,\n",
              " 'playhouse': 20602,\n",
              " 'wickedly': 11311,\n",
              " 'fit': 1183,\n",
              " 'labratory': 52081,\n",
              " 'lifeline': 40862,\n",
              " 'screaming': 1930,\n",
              " 'fix': 4290,\n",
              " 'cineliterate': 52082,\n",
              " 'fic': 52083,\n",
              " 'fia': 52084,\n",
              " 'fig': 34717,\n",
              " 'fmvs': 52085,\n",
              " 'fie': 52086,\n",
              " 'reentered': 52087,\n",
              " 'fin': 30577,\n",
              " 'doctresses': 52088,\n",
              " 'fil': 52089,\n",
              " 'zucker': 12609,\n",
              " 'ached': 31934,\n",
              " 'counsil': 52091,\n",
              " 'paterfamilias': 52092,\n",
              " 'songwriter': 13888,\n",
              " 'shivam': 34718,\n",
              " 'hurting': 9657,\n",
              " 'effects': 302,\n",
              " 'slauther': 52093,\n",
              " \"'flame'\": 52094,\n",
              " 'sommerset': 52095,\n",
              " 'interwhined': 52096,\n",
              " 'whacking': 27641,\n",
              " 'bartok': 52097,\n",
              " 'barton': 8778,\n",
              " 'frewer': 21912,\n",
              " \"fi'\": 52098,\n",
              " 'ingrid': 6195,\n",
              " 'stribor': 30578,\n",
              " 'approporiately': 52099,\n",
              " 'wobblyhand': 52100,\n",
              " 'tantalisingly': 52101,\n",
              " 'ankylosaurus': 52102,\n",
              " 'parasites': 17637,\n",
              " 'childen': 52103,\n",
              " \"jenkins'\": 52104,\n",
              " 'metafiction': 52105,\n",
              " 'golem': 17638,\n",
              " 'indiscretion': 40863,\n",
              " \"reeves'\": 23386,\n",
              " \"inamorata's\": 57784,\n",
              " 'brittannica': 52107,\n",
              " 'adapt': 7919,\n",
              " \"russo's\": 30579,\n",
              " 'guitarists': 48249,\n",
              " 'abbott': 10556,\n",
              " 'abbots': 40864,\n",
              " 'lanisha': 17652,\n",
              " 'magickal': 40866,\n",
              " 'mattter': 52108,\n",
              " \"'willy\": 52109,\n",
              " 'pumpkins': 34719,\n",
              " 'stuntpeople': 52110,\n",
              " 'estimate': 30580,\n",
              " 'ugghhh': 40867,\n",
              " 'gameplay': 11312,\n",
              " \"wern't\": 52111,\n",
              " \"n'sync\": 40868,\n",
              " 'sickeningly': 16120,\n",
              " 'chiara': 40869,\n",
              " 'disturbed': 4014,\n",
              " 'portmanteau': 40870,\n",
              " 'ineffectively': 52112,\n",
              " \"duchonvey's\": 82146,\n",
              " \"nasty'\": 37522,\n",
              " 'purpose': 1288,\n",
              " 'lazers': 52115,\n",
              " 'lightened': 28108,\n",
              " 'kaliganj': 52116,\n",
              " 'popularism': 52117,\n",
              " \"damme's\": 18514,\n",
              " 'stylistics': 30581,\n",
              " 'mindgaming': 52118,\n",
              " 'spoilerish': 46452,\n",
              " \"'corny'\": 52120,\n",
              " 'boerner': 34721,\n",
              " 'olds': 6795,\n",
              " 'bakelite': 52121,\n",
              " 'renovated': 27642,\n",
              " 'forrester': 27643,\n",
              " \"lumiere's\": 52122,\n",
              " 'gaskets': 52027,\n",
              " 'needed': 887,\n",
              " 'smight': 34722,\n",
              " 'master': 1300,\n",
              " \"edie's\": 25908,\n",
              " 'seeber': 40871,\n",
              " 'hiya': 52123,\n",
              " 'fuzziness': 52124,\n",
              " 'genesis': 14900,\n",
              " 'rewards': 12610,\n",
              " 'enthrall': 30582,\n",
              " \"'about\": 40872,\n",
              " \"recollection's\": 52125,\n",
              " 'mutilated': 11042,\n",
              " 'fatherlands': 52126,\n",
              " \"fischer's\": 52127,\n",
              " 'positively': 5402,\n",
              " '270': 34708,\n",
              " 'ahmed': 34723,\n",
              " 'zatoichi': 9839,\n",
              " 'bannister': 13889,\n",
              " 'anniversaries': 52130,\n",
              " \"helm's\": 30583,\n",
              " \"'work'\": 52131,\n",
              " 'exclaimed': 34724,\n",
              " \"'unfunny'\": 52132,\n",
              " '274': 52032,\n",
              " 'feeling': 547,\n",
              " \"wanda's\": 52134,\n",
              " 'dolan': 33269,\n",
              " '278': 52136,\n",
              " 'peacoat': 52137,\n",
              " 'brawny': 40873,\n",
              " 'mishra': 40874,\n",
              " 'worlders': 40875,\n",
              " 'protags': 52138,\n",
              " 'skullcap': 52139,\n",
              " 'dastagir': 57599,\n",
              " 'affairs': 5625,\n",
              " 'wholesome': 7802,\n",
              " 'hymen': 52140,\n",
              " 'paramedics': 25249,\n",
              " 'unpersons': 52141,\n",
              " 'heavyarms': 52142,\n",
              " 'affaire': 52143,\n",
              " 'coulisses': 52144,\n",
              " 'hymer': 40876,\n",
              " 'kremlin': 52145,\n",
              " 'shipments': 30584,\n",
              " 'pixilated': 52146,\n",
              " \"'00s\": 30585,\n",
              " 'diminishing': 18515,\n",
              " 'cinematic': 1360,\n",
              " 'resonates': 14901,\n",
              " 'simplify': 40877,\n",
              " \"nature'\": 40878,\n",
              " 'temptresses': 40879,\n",
              " 'reverence': 16825,\n",
              " 'resonated': 19505,\n",
              " 'dailey': 34725,\n",
              " '2\\x85': 52147,\n",
              " 'treize': 27644,\n",
              " 'majo': 52148,\n",
              " 'kiya': 21913,\n",
              " 'woolnough': 52149,\n",
              " 'thanatos': 39800,\n",
              " 'sandoval': 35734,\n",
              " 'dorama': 40882,\n",
              " \"o'shaughnessy\": 52150,\n",
              " 'tech': 4991,\n",
              " 'fugitives': 32021,\n",
              " 'teck': 30586,\n",
              " \"'e'\": 76128,\n",
              " 'doesn’t': 40884,\n",
              " 'purged': 52152,\n",
              " 'saying': 660,\n",
              " \"martians'\": 41098,\n",
              " 'norliss': 23421,\n",
              " 'dickey': 27645,\n",
              " 'dicker': 52155,\n",
              " \"'sependipity\": 52156,\n",
              " 'padded': 8425,\n",
              " 'ordell': 57795,\n",
              " \"sturges'\": 40885,\n",
              " 'independentcritics': 52157,\n",
              " 'tempted': 5748,\n",
              " \"atkinson's\": 34727,\n",
              " 'hounded': 25250,\n",
              " 'apace': 52158,\n",
              " 'clicked': 15497,\n",
              " \"'humor'\": 30587,\n",
              " \"martino's\": 17180,\n",
              " \"'supporting\": 52159,\n",
              " 'warmongering': 52035,\n",
              " \"zemeckis's\": 34728,\n",
              " 'lube': 21914,\n",
              " 'shocky': 52160,\n",
              " 'plate': 7479,\n",
              " 'plata': 40886,\n",
              " 'sturgess': 40887,\n",
              " \"nerds'\": 40888,\n",
              " 'plato': 20603,\n",
              " 'plath': 34729,\n",
              " 'platt': 40889,\n",
              " 'mcnab': 52162,\n",
              " 'clumsiness': 27646,\n",
              " 'altogether': 3902,\n",
              " 'massacring': 42587,\n",
              " 'bicenntinial': 52163,\n",
              " 'skaal': 40890,\n",
              " 'droning': 14363,\n",
              " 'lds': 8779,\n",
              " 'jaguar': 21915,\n",
              " \"cale's\": 34730,\n",
              " 'nicely': 1780,\n",
              " 'mummy': 4591,\n",
              " \"lot's\": 18516,\n",
              " 'patch': 10089,\n",
              " 'kerkhof': 50205,\n",
              " \"leader's\": 52164,\n",
              " \"'movie\": 27647,\n",
              " 'uncomfirmed': 52165,\n",
              " 'heirloom': 40891,\n",
              " 'wrangle': 47363,\n",
              " 'emotion\\x85': 52166,\n",
              " \"'stargate'\": 52167,\n",
              " 'pinoy': 40892,\n",
              " 'conchatta': 40893,\n",
              " 'broeke': 41131,\n",
              " 'advisedly': 40894,\n",
              " \"barker's\": 17639,\n",
              " 'descours': 52169,\n",
              " 'lots': 775,\n",
              " 'lotr': 9262,\n",
              " 'irs': 9882,\n",
              " 'lott': 52170,\n",
              " 'xvi': 40895,\n",
              " 'irk': 34731,\n",
              " 'irl': 52171,\n",
              " 'ira': 6890,\n",
              " 'belzer': 21916,\n",
              " 'irc': 52172,\n",
              " 'ire': 27648,\n",
              " 'requisites': 40896,\n",
              " 'discipline': 7696,\n",
              " 'lyoko': 52964,\n",
              " 'extend': 11313,\n",
              " 'nature': 876,\n",
              " \"'dickie'\": 52173,\n",
              " 'optimist': 40897,\n",
              " 'lapping': 30589,\n",
              " 'superficial': 3903,\n",
              " 'vestment': 52174,\n",
              " 'extent': 2826,\n",
              " 'tendons': 52175,\n",
              " \"heller's\": 52176,\n",
              " 'quagmires': 52177,\n",
              " 'miyako': 52178,\n",
              " 'moocow': 20604,\n",
              " \"coles'\": 52179,\n",
              " 'lookit': 40898,\n",
              " 'ravenously': 52180,\n",
              " 'levitating': 40899,\n",
              " 'perfunctorily': 52181,\n",
              " 'lookin': 30590,\n",
              " \"lot'\": 40901,\n",
              " 'lookie': 52182,\n",
              " 'fearlessly': 34873,\n",
              " 'libyan': 52184,\n",
              " 'fondles': 40902,\n",
              " 'gopher': 35717,\n",
              " 'wearying': 40904,\n",
              " \"nz's\": 52185,\n",
              " 'minuses': 27649,\n",
              " 'puposelessly': 52186,\n",
              " 'shandling': 52187,\n",
              " 'decapitates': 31271,\n",
              " 'humming': 11932,\n",
              " \"'nother\": 40905,\n",
              " 'smackdown': 21917,\n",
              " 'underdone': 30591,\n",
              " 'frf': 40906,\n",
              " 'triviality': 52188,\n",
              " 'fro': 25251,\n",
              " 'bothers': 8780,\n",
              " \"'kensington\": 52189,\n",
              " 'much': 76,\n",
              " 'muco': 34733,\n",
              " 'wiseguy': 22618,\n",
              " \"richie's\": 27651,\n",
              " 'tonino': 40907,\n",
              " 'unleavened': 52190,\n",
              " 'fry': 11590,\n",
              " \"'tv'\": 40908,\n",
              " 'toning': 40909,\n",
              " 'obese': 14364,\n",
              " 'sensationalized': 30592,\n",
              " 'spiv': 40910,\n",
              " 'spit': 6262,\n",
              " 'arkin': 7367,\n",
              " 'charleton': 21918,\n",
              " 'jeon': 16826,\n",
              " 'boardroom': 21919,\n",
              " 'doubts': 4992,\n",
              " 'spin': 3087,\n",
              " 'hepo': 53086,\n",
              " 'wildcat': 27652,\n",
              " 'venoms': 10587,\n",
              " 'misconstrues': 52194,\n",
              " 'mesmerising': 18517,\n",
              " 'misconstrued': 40911,\n",
              " 'rescinds': 52195,\n",
              " 'prostrate': 52196,\n",
              " 'majid': 40912,\n",
              " 'climbed': 16482,\n",
              " 'canoeing': 34734,\n",
              " 'majin': 52198,\n",
              " 'animie': 57807,\n",
              " 'sylke': 40913,\n",
              " 'conditioned': 14902,\n",
              " 'waddell': 40914,\n",
              " '3\\x85': 52199,\n",
              " 'hyperdrive': 41191,\n",
              " 'conditioner': 34735,\n",
              " 'bricklayer': 53156,\n",
              " 'hong': 2579,\n",
              " 'memoriam': 52201,\n",
              " 'inventively': 30595,\n",
              " \"levant's\": 25252,\n",
              " 'portobello': 20641,\n",
              " 'remand': 52203,\n",
              " 'mummified': 19507,\n",
              " 'honk': 27653,\n",
              " 'spews': 19508,\n",
              " 'visitations': 40915,\n",
              " 'mummifies': 52204,\n",
              " 'cavanaugh': 25253,\n",
              " 'zeon': 23388,\n",
              " \"jungle's\": 40916,\n",
              " 'viertel': 34736,\n",
              " 'frenchmen': 27654,\n",
              " 'torpedoes': 52205,\n",
              " 'schlessinger': 52206,\n",
              " 'torpedoed': 34737,\n",
              " 'blister': 69879,\n",
              " 'cinefest': 52207,\n",
              " 'furlough': 34738,\n",
              " 'mainsequence': 52208,\n",
              " 'mentors': 40917,\n",
              " 'academic': 9097,\n",
              " 'stillness': 20605,\n",
              " 'academia': 40918,\n",
              " 'lonelier': 52209,\n",
              " 'nibby': 52210,\n",
              " \"losers'\": 52211,\n",
              " 'cineastes': 40919,\n",
              " 'corporate': 4452,\n",
              " 'massaging': 40920,\n",
              " 'bellow': 30596,\n",
              " 'absurdities': 19509,\n",
              " 'expetations': 53244,\n",
              " 'nyfiken': 40921,\n",
              " 'mehras': 75641,\n",
              " 'lasse': 52212,\n",
              " 'visability': 52213,\n",
              " 'militarily': 33949,\n",
              " \"elder'\": 52214,\n",
              " 'gainsbourg': 19026,\n",
              " 'hah': 20606,\n",
              " 'hai': 13423,\n",
              " 'haj': 34739,\n",
              " 'hak': 25254,\n",
              " 'hal': 4314,\n",
              " 'ham': 4895,\n",
              " 'duffer': 53262,\n",
              " 'haa': 52216,\n",
              " 'had': 69,\n",
              " 'advancement': 11933,\n",
              " 'hag': 16828,\n",
              " \"hand'\": 25255,\n",
              " 'hay': 13424,\n",
              " 'mcnamara': 20607,\n",
              " \"mozart's\": 52217,\n",
              " 'duffel': 30734,\n",
              " 'haq': 30597,\n",
              " 'har': 13890,\n",
              " 'has': 47,\n",
              " 'hat': 2404,\n",
              " 'hav': 40922,\n",
              " 'haw': 30598,\n",
              " 'figtings': 52218,\n",
              " 'elders': 15498,\n",
              " 'underpanted': 52219,\n",
              " 'pninson': 52220,\n",
              " 'unequivocally': 27655,\n",
              " \"barbara's\": 23676,\n",
              " \"bello'\": 52222,\n",
              " 'indicative': 13000,\n",
              " 'yawnfest': 40923,\n",
              " 'hexploitation': 52223,\n",
              " \"loder's\": 52224,\n",
              " 'sleuthing': 27656,\n",
              " \"justin's\": 32625,\n",
              " \"'ball\": 52225,\n",
              " \"'summer\": 52226,\n",
              " \"'demons'\": 34938,\n",
              " \"mormon's\": 52228,\n",
              " \"laughton's\": 34740,\n",
              " 'debell': 52229,\n",
              " 'shipyard': 39727,\n",
              " 'unabashedly': 30600,\n",
              " 'disks': 40404,\n",
              " 'crowd': 2293,\n",
              " 'crowe': 10090,\n",
              " \"vancouver's\": 56437,\n",
              " 'mosques': 34741,\n",
              " 'crown': 6630,\n",
              " 'culpas': 52230,\n",
              " 'crows': 27657,\n",
              " 'surrell': 53347,\n",
              " 'flowless': 52232,\n",
              " 'sheirk': 52233,\n",
              " \"'three\": 40926,\n",
              " \"peterson'\": 52234,\n",
              " 'ooverall': 52235,\n",
              " 'perchance': 40927,\n",
              " 'bottom': 1324,\n",
              " 'chabert': 53366,\n",
              " 'sneha': 52236,\n",
              " 'inhuman': 13891,\n",
              " 'ichii': 52237,\n",
              " 'ursla': 52238,\n",
              " 'completly': 30601,\n",
              " 'moviedom': 40928,\n",
              " 'raddick': 52239,\n",
              " 'brundage': 51998,\n",
              " 'brigades': 40929,\n",
              " 'starring': 1184,\n",
              " \"'goal'\": 52240,\n",
              " 'caskets': 52241,\n",
              " 'willcock': 52242,\n",
              " \"threesome's\": 52243,\n",
              " \"mosque'\": 52244,\n",
              " \"cover's\": 52245,\n",
              " 'spaceships': 17640,\n",
              " 'anomalous': 40930,\n",
              " 'ptsd': 27658,\n",
              " 'shirdan': 52246,\n",
              " 'obscenity': 21965,\n",
              " 'lemmings': 30602,\n",
              " 'duccio': 30603,\n",
              " \"levene's\": 52247,\n",
              " \"'gorby'\": 52248,\n",
              " \"teenager's\": 25258,\n",
              " 'marshall': 5343,\n",
              " 'honeymoon': 9098,\n",
              " 'shoots': 3234,\n",
              " 'despised': 12261,\n",
              " 'okabasho': 52249,\n",
              " 'fabric': 8292,\n",
              " 'cannavale': 18518,\n",
              " 'raped': 3540,\n",
              " \"tutt's\": 52250,\n",
              " 'grasping': 17641,\n",
              " 'despises': 18519,\n",
              " \"thief's\": 40931,\n",
              " 'rapes': 8929,\n",
              " 'raper': 52251,\n",
              " \"eyre'\": 27659,\n",
              " 'walchek': 52252,\n",
              " \"elmo's\": 23389,\n",
              " 'perfumes': 40932,\n",
              " 'spurting': 21921,\n",
              " \"exposition'\\x85\": 52253,\n",
              " 'denoting': 52254,\n",
              " 'thesaurus': 34743,\n",
              " \"shoot'\": 40933,\n",
              " 'bonejack': 49762,\n",
              " 'simpsonian': 52256,\n",
              " 'hebetude': 30604,\n",
              " \"hallow's\": 34744,\n",
              " 'desperation\\x85': 52257,\n",
              " 'incinerator': 34745,\n",
              " 'congratulations': 10311,\n",
              " 'humbled': 52258,\n",
              " \"else's\": 5927,\n",
              " 'trelkovski': 40848,\n",
              " \"rape'\": 52259,\n",
              " \"'chapters'\": 59389,\n",
              " '1600s': 52260,\n",
              " 'martian': 7256,\n",
              " 'nicest': 25259,\n",
              " 'eyred': 52262,\n",
              " 'passenger': 9460,\n",
              " 'disgrace': 6044,\n",
              " 'moderne': 52263,\n",
              " 'barrymore': 5123,\n",
              " 'yankovich': 52264,\n",
              " 'moderns': 40934,\n",
              " 'studliest': 52265,\n",
              " 'bedsheet': 52266,\n",
              " 'decapitation': 14903,\n",
              " 'slurring': 52267,\n",
              " \"'nunsploitation'\": 52268,\n",
              " \"'character'\": 34746,\n",
              " 'cambodia': 9883,\n",
              " 'rebelious': 52269,\n",
              " 'pasadena': 27660,\n",
              " 'crowne': 40935,\n",
              " \"'bedchamber\": 52270,\n",
              " 'conjectural': 52271,\n",
              " 'appologize': 52272,\n",
              " 'halfassing': 52273,\n",
              " 'paycheque': 57819,\n",
              " 'palms': 20609,\n",
              " \"'islands\": 52274,\n",
              " 'hawked': 40936,\n",
              " 'palme': 21922,\n",
              " 'conservatively': 40937,\n",
              " 'larp': 64010,\n",
              " 'palma': 5561,\n",
              " 'smelling': 21923,\n",
              " 'aragorn': 13001,\n",
              " 'hawker': 52275,\n",
              " 'hawkes': 52276,\n",
              " 'explosions': 3978,\n",
              " 'loren': 8062,\n",
              " \"pyle's\": 52277,\n",
              " 'shootout': 6707,\n",
              " \"mike's\": 18520,\n",
              " \"driscoll's\": 52278,\n",
              " 'cogsworth': 40938,\n",
              " \"britian's\": 52279,\n",
              " 'childs': 34747,\n",
              " \"portrait's\": 52280,\n",
              " 'chain': 3629,\n",
              " 'whoever': 2500,\n",
              " 'puttered': 52281,\n",
              " 'childe': 52282,\n",
              " 'maywether': 52283,\n",
              " 'chair': 3039,\n",
              " \"rance's\": 52284,\n",
              " 'machu': 34748,\n",
              " 'ballet': 4520,\n",
              " 'grapples': 34749,\n",
              " 'summerize': 76155,\n",
              " 'freelance': 30606,\n",
              " \"andrea's\": 52286,\n",
              " '\\x91very': 52287,\n",
              " 'coolidge': 45882,\n",
              " 'mache': 18521,\n",
              " 'balled': 52288,\n",
              " 'grappled': 40940,\n",
              " 'macha': 18522,\n",
              " 'underlining': 21924,\n",
              " 'macho': 5626,\n",
              " 'oversight': 19510,\n",
              " 'machi': 25260,\n",
              " 'verbally': 11314,\n",
              " 'tenacious': 21925,\n",
              " 'windshields': 40941,\n",
              " 'paychecks': 18560,\n",
              " 'jerk': 3399,\n",
              " \"good'\": 11934,\n",
              " 'prancer': 34751,\n",
              " 'prances': 21926,\n",
              " 'olympus': 52289,\n",
              " 'lark': 21927,\n",
              " 'embark': 10788,\n",
              " 'gloomy': 7368,\n",
              " 'jehaan': 52290,\n",
              " 'turaqui': 52291,\n",
              " \"child'\": 20610,\n",
              " 'locked': 2897,\n",
              " 'pranced': 52292,\n",
              " 'exact': 2591,\n",
              " 'unattuned': 52293,\n",
              " 'minute': 786,\n",
              " 'skewed': 16121,\n",
              " 'hodgins': 40943,\n",
              " 'skewer': 34752,\n",
              " 'think\\x85': 52294,\n",
              " 'rosenstein': 38768,\n",
              " 'helmit': 52295,\n",
              " 'wrestlemanias': 34753,\n",
              " 'hindered': 16829,\n",
              " \"martha's\": 30607,\n",
              " 'cheree': 52296,\n",
              " \"pluckin'\": 52297,\n",
              " 'ogles': 40944,\n",
              " 'heavyweight': 11935,\n",
              " 'aada': 82193,\n",
              " 'chopping': 11315,\n",
              " 'strongboy': 61537,\n",
              " 'hegemonic': 41345,\n",
              " 'adorns': 40945,\n",
              " 'xxth': 41349,\n",
              " 'nobuhiro': 34754,\n",
              " 'capitães': 52301,\n",
              " 'kavogianni': 52302,\n",
              " 'antwerp': 13425,\n",
              " 'celebrated': 6541,\n",
              " 'roarke': 52303,\n",
              " 'baggins': 40946,\n",
              " 'cheeseburgers': 31273,\n",
              " 'matras': 52304,\n",
              " \"nineties'\": 52305,\n",
              " \"'craig'\": 52306,\n",
              " 'celebrates': 13002,\n",
              " 'unintentionally': 3386,\n",
              " 'drafted': 14365,\n",
              " 'climby': 52307,\n",
              " '303': 52308,\n",
              " 'oldies': 18523,\n",
              " 'climbs': 9099,\n",
              " 'honour': 9658,\n",
              " 'plucking': 34755,\n",
              " '305': 30077,\n",
              " 'address': 5517,\n",
              " 'menjou': 40947,\n",
              " \"'freak'\": 42595,\n",
              " 'dwindling': 19511,\n",
              " 'benson': 9461,\n",
              " 'white’s': 52310,\n",
              " 'shamelessness': 40948,\n",
              " 'impacted': 21928,\n",
              " 'upatz': 52311,\n",
              " 'cusack': 3843,\n",
              " \"flavia's\": 37570,\n",
              " 'effette': 52312,\n",
              " 'influx': 34756,\n",
              " 'boooooooo': 52313,\n",
              " 'dimitrova': 52314,\n",
              " 'houseman': 13426,\n",
              " 'bigas': 25262,\n",
              " 'boylen': 52315,\n",
              " 'phillipenes': 52316,\n",
              " 'fakery': 40949,\n",
              " \"grandpa's\": 27661,\n",
              " 'darnell': 27662,\n",
              " 'undergone': 19512,\n",
              " 'handbags': 52318,\n",
              " 'perished': 21929,\n",
              " 'pooped': 37781,\n",
              " 'vigour': 27663,\n",
              " 'opposed': 3630,\n",
              " 'etude': 52319,\n",
              " \"caine's\": 11802,\n",
              " 'doozers': 52320,\n",
              " 'photojournals': 34757,\n",
              " 'perishes': 52321,\n",
              " 'constrains': 34758,\n",
              " 'migenes': 40951,\n",
              " 'consoled': 30608,\n",
              " 'alastair': 16830,\n",
              " 'wvs': 52322,\n",
              " 'ooooooh': 52323,\n",
              " 'approving': 34759,\n",
              " 'consoles': 40952,\n",
              " 'disparagement': 52067,\n",
              " 'futureistic': 52325,\n",
              " 'rebounding': 52326,\n",
              " \"'date\": 52327,\n",
              " 'gregoire': 52328,\n",
              " 'rutherford': 21930,\n",
              " 'americanised': 34760,\n",
              " 'novikov': 82199,\n",
              " 'following': 1045,\n",
              " 'munroe': 34761,\n",
              " \"morita'\": 52329,\n",
              " 'christenssen': 52330,\n",
              " 'oatmeal': 23109,\n",
              " 'fossey': 25263,\n",
              " 'livered': 40953,\n",
              " 'listens': 13003,\n",
              " \"'marci\": 76167,\n",
              " \"otis's\": 52333,\n",
              " 'thanking': 23390,\n",
              " 'maude': 16022,\n",
              " 'extensions': 34762,\n",
              " 'ameteurish': 52335,\n",
              " \"commender's\": 52336,\n",
              " 'agricultural': 27664,\n",
              " 'convincingly': 4521,\n",
              " 'fueled': 17642,\n",
              " 'mahattan': 54017,\n",
              " \"paris's\": 40955,\n",
              " 'vulkan': 52339,\n",
              " 'stapes': 52340,\n",
              " 'odysessy': 52341,\n",
              " 'harmon': 12262,\n",
              " 'surfing': 4255,\n",
              " 'halloran': 23497,\n",
              " 'unbelieveably': 49583,\n",
              " \"'offed'\": 52342,\n",
              " 'quadrant': 30610,\n",
              " 'inhabiting': 19513,\n",
              " 'nebbish': 34763,\n",
              " 'forebears': 40956,\n",
              " 'skirmish': 34764,\n",
              " 'ocassionally': 52343,\n",
              " \"'resist\": 52344,\n",
              " 'impactful': 21931,\n",
              " 'spicier': 52345,\n",
              " 'touristy': 40957,\n",
              " \"'football'\": 52346,\n",
              " 'webpage': 40958,\n",
              " 'exurbia': 52348,\n",
              " 'jucier': 52349,\n",
              " 'professors': 14904,\n",
              " 'structuring': 34765,\n",
              " 'jig': 30611,\n",
              " 'overlord': 40959,\n",
              " 'disconnect': 25264,\n",
              " 'sniffle': 82204,\n",
              " 'slimeball': 40960,\n",
              " 'jia': 40961,\n",
              " 'milked': 16831,\n",
              " 'banjoes': 40962,\n",
              " 'jim': 1240,\n",
              " 'workforces': 52351,\n",
              " 'jip': 52352,\n",
              " 'rotweiller': 52353,\n",
              " 'mundaneness': 34766,\n",
              " \"'ninja'\": 52354,\n",
              " \"dead'\": 11043,\n",
              " \"cipriani's\": 40963,\n",
              " 'modestly': 20611,\n",
              " \"professor'\": 52355,\n",
              " 'shacked': 40964,\n",
              " 'bashful': 34767,\n",
              " 'sorter': 23391,\n",
              " 'overpowering': 16123,\n",
              " 'workmanlike': 18524,\n",
              " 'henpecked': 27665,\n",
              " 'sorted': 18525,\n",
              " \"jōb's\": 52357,\n",
              " \"'always\": 52358,\n",
              " \"'baptists\": 34768,\n",
              " 'dreamcatchers': 52359,\n",
              " \"'silence'\": 52360,\n",
              " 'hickory': 21932,\n",
              " 'fun\\x97yet': 52361,\n",
              " 'breakumentary': 52362,\n",
              " 'didn': 15499,\n",
              " 'didi': 52363,\n",
              " 'pealing': 52364,\n",
              " 'dispite': 40965,\n",
              " \"italy's\": 25265,\n",
              " 'instability': 21933,\n",
              " 'quarter': 6542,\n",
              " 'quartet': 12611,\n",
              " 'padmé': 52365,\n",
              " \"'bleedmedry\": 52366,\n",
              " 'pahalniuk': 52367,\n",
              " 'honduras': 52368,\n",
              " 'bursting': 10789,\n",
              " \"pablo's\": 41468,\n",
              " 'irremediably': 52370,\n",
              " 'presages': 40966,\n",
              " 'bowlegged': 57835,\n",
              " 'dalip': 65186,\n",
              " 'entering': 6263,\n",
              " 'newsradio': 76175,\n",
              " 'presaged': 54153,\n",
              " \"giallo's\": 27666,\n",
              " 'bouyant': 40967,\n",
              " 'amerterish': 52371,\n",
              " 'rajni': 18526,\n",
              " 'leeves': 30613,\n",
              " 'macauley': 34770,\n",
              " 'seriously': 615,\n",
              " 'sugercoma': 52372,\n",
              " 'grimstead': 52373,\n",
              " \"'fairy'\": 52374,\n",
              " 'zenda': 30614,\n",
              " \"'twins'\": 52375,\n",
              " 'realisation': 17643,\n",
              " 'highsmith': 27667,\n",
              " 'raunchy': 7820,\n",
              " 'incentives': 40968,\n",
              " 'flatson': 52377,\n",
              " 'snooker': 35100,\n",
              " 'crazies': 16832,\n",
              " 'crazier': 14905,\n",
              " 'grandma': 7097,\n",
              " 'napunsaktha': 52378,\n",
              " 'workmanship': 30615,\n",
              " 'reisner': 52379,\n",
              " \"sanford's\": 61309,\n",
              " '\\x91doña': 52380,\n",
              " 'modest': 6111,\n",
              " \"everything's\": 19156,\n",
              " 'hamer': 40969,\n",
              " \"couldn't'\": 52382,\n",
              " 'quibble': 13004,\n",
              " 'socking': 52383,\n",
              " 'tingler': 21934,\n",
              " 'gutman': 52384,\n",
              " 'lachlan': 40970,\n",
              " 'tableaus': 52385,\n",
              " 'headbanger': 52386,\n",
              " 'spoken': 2850,\n",
              " 'cerebrally': 34771,\n",
              " \"'road\": 23493,\n",
              " 'tableaux': 21935,\n",
              " \"proust's\": 40971,\n",
              " 'periodical': 40972,\n",
              " \"shoveller's\": 52388,\n",
              " 'tamara': 25266,\n",
              " 'affords': 17644,\n",
              " 'concert': 3252,\n",
              " \"yara's\": 87958,\n",
              " 'someome': 52389,\n",
              " 'lingering': 8427,\n",
              " \"abraham's\": 41514,\n",
              " 'beesley': 34772,\n",
              " 'cherbourg': 34773,\n",
              " 'kagan': 28627,\n",
              " 'snatch': 9100,\n",
              " \"miyazaki's\": 9263,\n",
              " 'absorbs': 25267,\n",
              " \"koltai's\": 40973,\n",
              " 'tingled': 64030,\n",
              " 'crossroads': 19514,\n",
              " 'rehab': 16124,\n",
              " 'falworth': 52392,\n",
              " 'sequals': 52393,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFP_XKVRp4_S",
        "colab_type": "text"
      },
      "source": [
        "## データの準備\n",
        "\n",
        "レビュー（整数の配列）は、ニューラルネットワークに投入する前に、テンソルに変換する必要があります。これには2つの方法があります。\n",
        "\n",
        "* 配列をワンホット（one-hot）エンコーディングと同じように、単語の出現を表す0と1のベクトルに変換します。例えば、[3, 5]という配列は、インデックス3と5を除いてすべてゼロの10,000次元のベクトルになります。そして、これをネットワークの最初の層、すなわち、浮動小数点のベクトルデータを扱うことができるDense（全結合）層とします。ただし、これは単語数×レビュー数の行列が必要なメモリ集約的な方法です。\n",
        "* もう一つの方法では、配列をパディングによって同じ長さに揃え、`サンプル数 * 長さの最大値`の形の整数テンソルにします。そして、この形式を扱うことができるEmbedding（埋め込み）層をネットワークの最初の層にします。\n",
        "\n",
        "このチュートリアルでは、後者を採用することにします。\n",
        "\n",
        "映画レビューは同じ長さでなければならないので、長さを標準化する [pad_sequences](https://www.tensorflow.org/versions/r1.10/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 関数を使うことにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQv-omsHurp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO5MBpyQdipD",
        "colab_type": "text"
      },
      "source": [
        "サンプルの長さを見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USSSBnkE-lky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bbf8210-416a-4e4e-e88d-2f1510a0e0ed"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoxZGyfjT5V",
        "colab_type": "text"
      },
      "source": [
        "次に、パディング済みの最初のサンプルを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG8X9cqi-lk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "029bfe47-2acb-49ef-bc14-3000c1f4ac66"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60d4mvaammC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965c0bbf-7ed1-4b51-a725-d25a8fed175e"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC5dvrb1az5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7df8124d-5de1-4b56-c546-ed956a4c1ef1"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLC02j2g-llC",
        "colab_type": "text"
      },
      "source": [
        "## モデルの構築\n",
        "\n",
        "ニューラルネットワークは、層を積み重ねることで構成されます。この際、２つの大きな決定が必要です。\n",
        "\n",
        "* モデルにいくつの**層**を設けるか？\n",
        "* 層ごとに何個の**隠れユニット**を使用するか？\n",
        "\n",
        "この例では、入力データは単語インデックスの配列で構成されています。推定の対象となるラベルは、0または1です。この問題のためのモデルを構築しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpKOoWgu-llD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ba56dbcf-bcd5-47eb-bc10-464978b9aaff"
      },
      "source": [
        "# 入力の形式は映画レビューで使われている語彙数（10,000語）\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PbKQ6mucuKL",
        "colab_type": "text"
      },
      "source": [
        "これらの層は、分類器を構成するため一列に積み重ねられます。\n",
        "\n",
        "1. 最初の層は`Embedding`（埋め込み）層です。この層は、整数にエンコードされた語彙を受け取り、それぞれの単語インデックスに対応する埋め込みベクトルを検索します。埋め込みベクトルは、モデルの訓練の中で学習されます。ベクトル化のために、出力行列には次元が１つ追加されます。その結果、次元は、`(batch, sequence, embedding)`となります。\n",
        "2. 次は、`GlobalAveragePooling1D`（１次元のグローバル平均プーリング）層です。この層は、それぞれのサンプルについて、シーケンスの次元方向に平均値をもとめ、固定長のベクトルを返します。この結果、モデルは最も単純な形で、可変長の入力を扱うことができるようになります。\n",
        "3. この固定長の出力ベクトルは、16個の隠れユニットを持つ全結合（`Dense`）層に受け渡されます。\n",
        "4. 最後の層は、1個の出力ノードに全結合されます。シグモイド（`sigmoid`）活性化関数を使うことで、値は確率あるいは確信度を表す0と1の間の浮動小数点数となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XMwnDOp-llH",
        "colab_type": "text"
      },
      "source": [
        "### 隠れユニット\n",
        "\n",
        "上記のモデルには、入力と出力の間に、2つの中間層あるいは「隠れ」層があります。出力（ユニット、ノード、またはニューロン）は、その層の内部表現の次元数です。言い換えると、このネットワークが学習によって内部表現を獲得する際の自由度ということです。\n",
        "\n",
        "モデルにより多くの隠れユニットがある場合（内部表現空間の次元数がより大きい場合）、または、より多くの層がある場合、あるいはその両方の場合、ネットワークはより複雑な内部表現を学習することができます。しかしながら、その結果として、ネットワークの計算量が多くなるほか、学習してほしくないパターンを学習するようになります。学習してほしくないパターンとは、訓練データでの性能は向上するものの、テスト用データの性能が向上しないパターンです。この問題を**過学習**（*overfitting*）といいます。この問題は後ほど検証することになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4EqVWg4-llM",
        "colab_type": "text"
      },
      "source": [
        "### 損失関数とオプティマイザ\n",
        "\n",
        "モデルを訓練するには、損失関数とオプティマイザが必要です。今回の問題は二値分類問題であり、モデルの出力は確率（1ユニットの層とシグモイド活性化関数）であるため、損失関数として`binary_crossentropy`（2値のクロスエントロピー）関数を使用することにします。\n",
        "\n",
        "損失関数の候補はこれだけではありません。例えば、`mean_squared_error`（平均二乗誤差）を使うこともできます。しかし、一般的には、確率を扱うには`binary_crossentropy`の方が適しています。`binary_crossentropy`は、確率分布の間の「距離」を測定する尺度です。今回の場合には、真の分布と予測値の分布の間の距離ということになります。\n",
        "\n",
        "後ほど、回帰問題を検証する際には（例えば家屋の値段を推定するとか）、もう一つの損失関数である`mean_squared_error`（平均二乗誤差）の使い方を目にすることになります。\n",
        "\n",
        "さて、モデルのオプティマイザと損失関数を設定しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr0GP-cQ-llN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCWYwkug-llQ",
        "colab_type": "text"
      },
      "source": [
        "## 検証用データを作る\n",
        "\n",
        "訓練を行う際、モデルが見ていないデータでの正解率を検証したいと思います。もとの訓練用データから、10,000個のサンプルを取り分けて**検証用データ**（*validation set*）を作ります。（なぜ、ここでテスト用データを使わないのでしょう？ 今回の目的は、訓練用データだけを使って、モデルの開発とチューニングを行うことです。その後、テスト用データを1回だけ使い、正解率を検証するのです。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NpcXY9--llS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jv_fzP-llU",
        "colab_type": "text"
      },
      "source": [
        "## モデルの訓練\n",
        "\n",
        "512個のサンプルからなるミニバッチを使って、40エポックモデルを訓練します。この結果、`x_train`と`y_train`に含まれるすべてのサンプルを40回繰り返すことになります。訓練中、検証用データの10,000サンプルを用いて、モデルの損失と正解率をモニタリングします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXSGrjWZ-llW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68469176-25e4-41c3-b895-f3b9eefedf2b"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.6872\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.7099 - val_loss: 0.6801 - val_accuracy: 0.7315\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.7550 - val_loss: 0.6628 - val_accuracy: 0.7450\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6472 - accuracy: 0.7745 - val_loss: 0.6360 - val_accuracy: 0.7689\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6127 - accuracy: 0.7937 - val_loss: 0.5999 - val_accuracy: 0.7844\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5692 - accuracy: 0.8121 - val_loss: 0.5576 - val_accuracy: 0.8053\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5211 - accuracy: 0.8320 - val_loss: 0.5137 - val_accuracy: 0.8220\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4735 - accuracy: 0.8485 - val_loss: 0.4726 - val_accuracy: 0.8342\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4309 - accuracy: 0.8584 - val_loss: 0.4365 - val_accuracy: 0.8438\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3925 - accuracy: 0.8719 - val_loss: 0.4069 - val_accuracy: 0.8521\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3604 - accuracy: 0.8816 - val_loss: 0.3829 - val_accuracy: 0.8579\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3330 - accuracy: 0.8895 - val_loss: 0.3634 - val_accuracy: 0.8631\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3103 - accuracy: 0.8950 - val_loss: 0.3479 - val_accuracy: 0.8681\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2904 - accuracy: 0.9011 - val_loss: 0.3351 - val_accuracy: 0.8704\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2734 - accuracy: 0.9068 - val_loss: 0.3244 - val_accuracy: 0.8742\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2579 - accuracy: 0.9112 - val_loss: 0.3159 - val_accuracy: 0.8776\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2443 - accuracy: 0.9161 - val_loss: 0.3102 - val_accuracy: 0.8767\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2320 - accuracy: 0.9209 - val_loss: 0.3042 - val_accuracy: 0.8800\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2206 - accuracy: 0.9239 - val_loss: 0.2991 - val_accuracy: 0.8801\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2102 - accuracy: 0.9283 - val_loss: 0.2950 - val_accuracy: 0.8828\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2004 - accuracy: 0.9323 - val_loss: 0.2922 - val_accuracy: 0.8824\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1916 - accuracy: 0.9357 - val_loss: 0.2901 - val_accuracy: 0.8840\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1832 - accuracy: 0.9391 - val_loss: 0.2876 - val_accuracy: 0.8834\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1753 - accuracy: 0.9431 - val_loss: 0.2865 - val_accuracy: 0.8841\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9468 - val_loss: 0.2859 - val_accuracy: 0.8846\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.9494 - val_loss: 0.2860 - val_accuracy: 0.8846\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1551 - accuracy: 0.9507 - val_loss: 0.2858 - val_accuracy: 0.8847\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1482 - accuracy: 0.9546 - val_loss: 0.2857 - val_accuracy: 0.8851\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1424 - accuracy: 0.9571 - val_loss: 0.2867 - val_accuracy: 0.8855\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1366 - accuracy: 0.9593 - val_loss: 0.2880 - val_accuracy: 0.8857\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1311 - accuracy: 0.9616 - val_loss: 0.2896 - val_accuracy: 0.8858\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1263 - accuracy: 0.9637 - val_loss: 0.2909 - val_accuracy: 0.8855\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9651 - val_loss: 0.2925 - val_accuracy: 0.8851\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1167 - accuracy: 0.9671 - val_loss: 0.2948 - val_accuracy: 0.8852\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1122 - accuracy: 0.9687 - val_loss: 0.2972 - val_accuracy: 0.8841\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9705 - val_loss: 0.2994 - val_accuracy: 0.8854\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9719 - val_loss: 0.3022 - val_accuracy: 0.8841\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0996 - accuracy: 0.9733 - val_loss: 0.3052 - val_accuracy: 0.8833\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 0.9751 - val_loss: 0.3082 - val_accuracy: 0.8828\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9757 - val_loss: 0.3108 - val_accuracy: 0.8824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEGuDVuzb5r",
        "colab_type": "text"
      },
      "source": [
        "## モデルの評価\n",
        "\n",
        "さて、モデルの性能を見てみましょう。2つの値が返されます。損失（エラーを示す数値であり、小さい方が良い）と正解率です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73d550de-1ce4-4a6c-e24b-a864e028f422"
      },
      "source": [
        "results = model.evaluate(test_data,  test_labels, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 1s - loss: 0.3312 - accuracy: 0.8725\n",
            "[0.33118608593940735, 0.8724799752235413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1iEXVTR0Z2t",
        "colab_type": "text"
      },
      "source": [
        "この、かなり素朴なアプローチでも87%前後の正解率を達成しました。もっと高度なアプローチを使えば、モデルの正解率は95%に近づけることもできるでしょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KggXVeL-llZ",
        "colab_type": "text"
      },
      "source": [
        "## 正解率と損失の時系列グラフを描く\n",
        "\n",
        "`model.fit()` は、訓練中に発生したすべてのことを記録した辞書を含む`History` オブジェクトを返します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcvSXvhp-llb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b442bcb5-3e52-4f43-c720-df369bb911fc"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRKsqL40-lle",
        "colab_type": "text"
      },
      "source": [
        "4つのエントリがあります。それぞれが、訓練と検証の際にモニターしていた指標を示します。これを使って、訓練時と検証時の損失を比較するグラフと、訓練時と検証時の正解率を比較するグラフを作成することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGoYf2Js-lle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f1a84769-e46f-4ab8-f0cd-eb727a97e94e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXx-xOv-llh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "02d4f259-a621-4b4f-9ad8-6795d7ae0bf6"
      },
      "source": [
        "plt.clf()   # 図のクリア\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFEmZ5zq-llk",
        "colab_type": "text"
      },
      "source": [
        "上記のグラフでは、点が訓練時の損失と正解率を、実線が検証時の損失と正解率を表しています。\n",
        "\n",
        "訓練時の損失がエポックごとに**減少**し、訓練時の正解率がエポックごとに**上昇**していることに気がつくはずです。繰り返すごとに指定された数値指標を最小化する勾配降下法を最適化に使用している場合に期待される動きです。\n",
        "\n",
        "これは、検証時の損失と正解率には当てはまりません。20エポックを過ぎたあたりから、横ばいになっているようです。これが、過学習の一例です。モデルの性能が、訓練用データでは高い一方で、見たことの無いデータではそれほど高くないというものです。このポイントをすぎると、モデルが最適化しすぎて、訓練用データでは特徴的であるが、テスト用データには一般化できない内部表現を学習しています。\n",
        "\n",
        "このケースの場合、20エポックを過ぎたあたりで訓練をやめることで、過学習を防止することが出来ます。後ほど、コールバックを使って、これを自動化する方法を紹介します。"
      ]
    }
  ]
}